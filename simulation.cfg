#
# Simulation parameters
#

# Experiment Configurations

experimento = "ql";

experimentos :{
	reactive :{
		nbExp = 0;
	},
	ql:{
		nbExp = 1;
		rondasAprendizaje = 10;
		rondasTest = 3;
		fresh = 0; #0 para empezar con tabla ql nueva, 1 para empezar desde el archivo (continuar aprendizaje)
	},
	ann:{
		nbExp = 2;
	}
}
# Agent Configurations

agents :{
 		blendConstante:	{ 	behaviors 	= ["seek", "obstacleAvoidance"];
							weights 	= [0.700, 0.300];	},

		agenteOnlySeek:	{ 	behaviors 	= ["seek"];
							weights 	= [1.000];	},

		agenteOnlyAvoidObstacles:	{ 	behaviors 	= ["obstacleAvoidance"];
							weights 	= [1.000];	},

		#Requiere los parametros para discretizar los pesos en la Qtable
		qlInit:	{ 			behaviors 	= ["seek", "obstacleAvoidance"];
							wPosibles = 5; #[0.1 0.3 0.5 0.7 0.9] #wDiscretizacion = 0.200;
							qValInit = 0.000;
							file = "./src/steering_behaviors_controller/qTable.txt"; },

		#Requiere los parametros para cargar los pesos del QtableFile
		qlLoad:	{ 			behaviors 	= ["seek", "obstacleAvoidance"];
							wPosibles = 5;
							sSize = 4; #Valores de estado de entrada
							file = "./src/steering_behaviors_controller/qTable.txt"; },

		qlTest:	{ 			behaviors 	= ["seek", "obstacleAvoidance"];
							wPosibles = 5;
							sSize = 4; #Valores de estado de entrada
							file = "./src/steering_behaviors_controller/qTable.txt"; },

		#Requiere los parametros realizar el aprendizaje
		qlTrain:	{ 		behaviors 	= ["seek", "obstacleAvoidance"];
							minDeltaVisitas = 5;
							#Refuerzo:(id behavior, reinforcementState, reinforcementValue, message)
							refuerzos =	( 	(0, 0.200, 1.000, "objetivo"),
											(1, 0.800, -0.800, "peligroDeColision") );
							qValMax = 1.000;
							qValMin = -1.000;
							dTpunish = -0.01; #punishment per second
							gamma = 0.800; }
		};

############################
# Behaviors Configurations #
############################

behaviors : {

# Seek Behavior Configuration

	seek: 	{ 	name 			= "seekReactive";
				type			= "seek";
				variablesDeEstado		= 1;
				desiredV		= 1.000;

				discret = "iregular";
				vectorEstados = [0.000, 0.200, 0.300, 1.000, 5.000, 10.000];

				minEstado		= 0.000 ;
				maxEstado		= 20.000 ;
				paso			= 5.000;

				toleranceToTarget 	= 0.290; },

# Avoid Obstacles Behavior Configuration

	obstacleAvoidance:	{ 	name 			= "avoidObstaclesReactive";
							type			= "avoidObstacles";
							variablesDeEstado		= 3;
							desiredV = 1.000;

							discret = "iregular";
							vectorEstados = [0.000, 0.200, 0.400, 0.600, 0.800, 1.000, 1.200, 1.400, 1.600, 1.800, 2.000, 2.200, 2.400, 2.600, 2.800, 3.000, 4.000, 5.000];

							distMax 		= 5.000;
							distMin 		= 0.9;
							haz 			= 270;
							prescicion		= 1.000;

							minEstado		= 0.000 ;
							maxEstado		= 2.000 ;
							paso			= 0.500 },

# Flee Behavior Configuration

	fleeReactive: 	{ 	name 			= "fleeReactive";
						type			= "flee";
						targetX 		= 17.000;
						targetY 		= 20.000;
						variables		= 2;
						toleranceToTarget 	= 0.200; }

		};

#Luego de añadir la configuracion del comportamiento añadir la instanciacion en el metodo Factory::pickBehavior de Factory.cpp
