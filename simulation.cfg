#
# Simulation parameters
# 

simulationParams :
{
	agentsOnSimulation = ["agenteAprendiendo"];
};

# Agent Configurations

agents = ( 	{ 	type 		= "agenteReactivo";
				behaviors 	= ["seekReactive", "avoidObstaclesReactive"];
				weights 	= [0.200, 0.800];
				seleccionPesos	= "constW";	},

			{ 	type 		= "agenteOnlySeek";
				behaviors 	= ["seekReactive"];
				weights 	= [1.000];
				seleccionPesos	= "constWOnlySeek";	},

			{ 	type 		= "agenteOnlyAvoidObstacles";
				behaviors 	= ["avoidObstaclesReactive"];
				weights 	= [1.000];
				seleccionPesos	= "constWOnlyAO";	},

			{ 	type 		= "agenteAprendiendo";
				behaviors 	= ["seekRL", "avoidObstaclesRL"];
				weights 	= [0.200, 0.800];
				seleccionPesos	= "qvalueW";	},

			{ 	type 		= "agentePruebaAprendizaje";
				behaviors 	= ["seekRL", "avoidObstaclesRL"];
				weights 	= [0.200, 0.800];	
				seleccionPesos	= "constQvalueW";	},

			{ 	type 		= "agenteMuestra";
				behaviors 	= ["seekRL", "avoidObstaclesRL"];
				weights 	= [0.200, 0.800];	
				seleccionPesos	= "constAnnW";	} );

############################
# Behaviors Configurations #
############################

# Seek Behavior Configuration

seekBehaviors : {
	seekReactive: 	{ 	name 			= "seekReactive";
						type			= "seek";
						targetX 		= 17.000;
						targetY 		= 20.000;
						desiredV		= 0.250;
						variablesDeEstado		= 1;
						minEstado		= 0.000 ;
						maxEstado		= 10.000 ;
						paso			= 0.200;
						toleranceToTarget 	= 0.200; },

	seekRL:			{ 	name 			= "seekRL";
						type			= "seek";
						targetX 		= 17.000;
						targetY 		= 20.000;
						desiredV		= 0.250;
						variablesDeEstado		= 1;
						minEstado		= 0.000 ;
						maxEstado		= 20.000 ;
						paso			= 5.000;
						toleranceToTarget 	= 0.200; } };

# Avoid Obstacles Behavior Configuration

avoidObstaclesBehaviors : {
	avoidObstaclesReactive:	{ 	name 			= "avoidObstaclesReactive";
								type			= "avoidObstacles";
								variables		= 1;
								distMax 		= 2.000;
								distMin 		= 1.000;
								haz 			= 270;
								prescicion		= 1.000;
								variablesDeEstado		= 3;
								minEstado		= 0.000 ;
								maxEstado		= 2.000 ;
								paso			= 0.400;
								sectores		= 3; },

	avoidObstaclesRL: 		{ 	name 			= "avoidObstaclesRL";
								type			= "avoidObstacles";
								distMax 		= 2.000;
								variables		= 1;
								distMin 		= 1.000;
								haz 			= 270;
								prescicion		= 1.000;
								variablesDeEstado		= 3;
								minEstado		= 0.000 ;
								maxEstado		= 2.000 ;
								paso			= 0.500;
								sectores		= 3; } };

# Flee Behavior Configuration

fleeBehaviors : {
	fleeReactive: 	{ 	name 			= "fleeReactive";
						type			= "flee";
						targetX 		= 17.000;
						targetY 		= 20.000;
						variables		= 2;
						toleranceToTarget 	= 0.200; },

	fleeRL:			{ 	name 			= "fleeRL";
						type			= "flee";
						targetX 		= 14.000;
						targetY 		= 0.000;
						variables		= 2;
						toleranceToTarget 	= 0.200; } };

#Luego de añadir la configuracion del comportamiento añadir la instanciacion en el metodo Factory::pickBehavior de Factory.cpp

# wSelector Configuration

weights : {
			constW:			{ 	type = "constW";
								ceroRules =	( (1, 2.000) );
							},

			constWOnlySeek:	{ 	type = "constW";
								ceroRules =	( );
							},

			constWOnlyAO:	{ 	type = "constW";
								ceroRules =	( (0, 2.000) );
							},

			qvalueW:		{	type = "qvalueW";
								#wDiscretizacion = 0.200;
								wPosibles = 6;
								#[0.0 0.2 0.4 0.6 0.8 1.0]
								minDeltaVisitas = 5;	
								#para el generador de problemas
								refuerzos =	( (0, 0.000, 0.200), (1, 0.000, -0.300) );
								qValInit = 0.200;
								qValMax = 1.000;
								qValMin = -1.000;
								dTpunish = -0.050;
							},

			constQvalueW:	{ 	type = "constQvalueW";
							},

			constAnnW:		{ 	type = "constAnnW";
							} 
			};

